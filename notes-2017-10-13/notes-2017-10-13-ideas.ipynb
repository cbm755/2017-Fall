{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UBC Scientific Software Seminar\n",
    "\n",
    "October 13, 2017\n",
    "\n",
    "* Preprocesing\n",
    "* Model selection with cross-validation\n",
    "  * Random forest\n",
    "  * Gradient boosting classifier\n",
    "  * Logistic regression\n",
    "  * K-nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "X = titanic.preprocessing(data)\n",
    "y = data['Survived']\n",
    "\n",
    "test = pd.read_csv('test.csv')\n",
    "submit = titanic.preprocessing(test)\n",
    "submit['Deck_T'] = 0\n",
    "submit = submit[X.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 27 columns):\n",
      "Pclass            891 non-null int64\n",
      "Age               891 non-null float64\n",
      "SibSp             891 non-null int64\n",
      "Parch             891 non-null int64\n",
      "Fare              891 non-null float64\n",
      "Gender            891 non-null int64\n",
      "Alone             891 non-null int64\n",
      "Title_Dr          891 non-null uint8\n",
      "Title_Master      891 non-null uint8\n",
      "Title_Military    891 non-null uint8\n",
      "Title_Miss        891 non-null uint8\n",
      "Title_Mr          891 non-null uint8\n",
      "Title_Mrs         891 non-null uint8\n",
      "Title_Rev         891 non-null uint8\n",
      "Title_Royalty     891 non-null uint8\n",
      "Deck_A            891 non-null uint8\n",
      "Deck_B            891 non-null uint8\n",
      "Deck_C            891 non-null uint8\n",
      "Deck_D            891 non-null uint8\n",
      "Deck_E            891 non-null uint8\n",
      "Deck_F            891 non-null uint8\n",
      "Deck_G            891 non-null uint8\n",
      "Deck_T            891 non-null uint8\n",
      "Deck_X            891 non-null uint8\n",
      "Embarked_C        891 non-null uint8\n",
      "Embarked_Q        891 non-null uint8\n",
      "Embarked_S        891 non-null uint8\n",
      "dtypes: float64(2), int64(5), uint8(20)\n",
      "memory usage: 66.2 KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 27 columns):\n",
      "Pclass            418 non-null int64\n",
      "Age               418 non-null float64\n",
      "SibSp             418 non-null int64\n",
      "Parch             418 non-null int64\n",
      "Fare              418 non-null float64\n",
      "Gender            418 non-null int64\n",
      "Alone             418 non-null int64\n",
      "Title_Dr          418 non-null uint8\n",
      "Title_Master      418 non-null uint8\n",
      "Title_Military    418 non-null uint8\n",
      "Title_Miss        418 non-null uint8\n",
      "Title_Mr          418 non-null uint8\n",
      "Title_Mrs         418 non-null uint8\n",
      "Title_Rev         418 non-null uint8\n",
      "Title_Royalty     418 non-null uint8\n",
      "Deck_A            418 non-null uint8\n",
      "Deck_B            418 non-null uint8\n",
      "Deck_C            418 non-null uint8\n",
      "Deck_D            418 non-null uint8\n",
      "Deck_E            418 non-null uint8\n",
      "Deck_F            418 non-null uint8\n",
      "Deck_G            418 non-null uint8\n",
      "Deck_T            418 non-null int64\n",
      "Deck_X            418 non-null uint8\n",
      "Embarked_C        418 non-null uint8\n",
      "Embarked_Q        418 non-null uint8\n",
      "Embarked_S        418 non-null uint8\n",
      "dtypes: float64(2), int64(6), uint8(19)\n",
      "memory usage: 34.0 KB\n"
     ]
    }
   ],
   "source": [
    "submit.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection with cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the [scikit-learn documentation](http://scikit-learn.org/stable/modules/ensemble.html#forest):\n",
    "\n",
    "> A random forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and use averaging to improve the predictive accuracy and control over-fitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the random forest class from scikit-learn and fit a model to our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>mean_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.808133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500.0</td>\n",
       "      <td>0.804743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.800293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200.0</td>\n",
       "      <td>0.800249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.799138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_estimators  mean_score\n",
       "1         100.0    0.808133\n",
       "3         500.0    0.804743\n",
       "0          10.0    0.800293\n",
       "2         200.0    0.800249\n",
       "4        1000.0    0.799138"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(columns=['n_estimators','mean_score'])\n",
    "\n",
    "for n in [10,100,200,500,1000]:\n",
    "            clf = RFC(n_estimators=n)\n",
    "            scores = cross_val_score(clf,X,y,cv=5)\n",
    "            results = results.append({'n_estimators':n,'mean_score':scores.mean()},ignore_index=True)\n",
    "    \n",
    "results.sort_values(by='mean_score',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_features</th>\n",
       "      <th>mean_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.817122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>200.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.815973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.814881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.814862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>200.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.814856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.813701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.812609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>200.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.811472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.810368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.809257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_estimators  max_features  mean_score\n",
       "2          100.0          15.0    0.817122\n",
       "6          200.0          15.0    0.815973\n",
       "3          100.0          20.0    0.814881\n",
       "10        1000.0          15.0    0.814862\n",
       "7          200.0          20.0    0.814856\n",
       "1          100.0          10.0    0.813701\n",
       "11        1000.0          20.0    0.812609\n",
       "5          200.0          10.0    0.811472\n",
       "9         1000.0          10.0    0.810368\n",
       "0          100.0           5.0    0.809257"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_estimators = [100,200,1000]\n",
    "max_features = [5,10,15,20]\n",
    "results = pd.DataFrame(columns=['n_estimators','max_features','mean_score'])\n",
    "\n",
    "for n in n_estimators:\n",
    "    for f in max_features:\n",
    "        clf = RFC(n_estimators=n,max_features=f)\n",
    "        scores = cross_val_score(clf,X,y,cv=5)\n",
    "        results = results.append({'n_estimators':n,'max_features':f,'mean_score':scores.mean()},ignore_index=True)\n",
    "    \n",
    "results.sort_values(by='mean_score',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>mean_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>200.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.831660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.827184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.822690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.822683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.820474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.820468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>200.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.820436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.819382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>200.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.818239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.795685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.790073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.782252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_estimators  max_depth  mean_score\n",
       "6          200.0        8.0    0.831660\n",
       "2          100.0        8.0    0.827184\n",
       "1          100.0        5.0    0.822690\n",
       "9         1000.0        5.0    0.822683\n",
       "11        1000.0       10.0    0.820474\n",
       "10        1000.0        8.0    0.820468\n",
       "5          200.0        5.0    0.820436\n",
       "3          100.0       10.0    0.819382\n",
       "7          200.0       10.0    0.818239\n",
       "0          100.0        2.0    0.795685\n",
       "8         1000.0        2.0    0.790073\n",
       "4          200.0        2.0    0.782252"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_estimators = [100,200,1000]\n",
    "max_depth = [2,5,8,10]\n",
    "results = pd.DataFrame(columns=['n_estimators','max_depth','mean_score'])\n",
    "\n",
    "for n in n_estimators:\n",
    "    for m in max_depth:\n",
    "        clf = RFC(n_estimators=n,max_depth=m)\n",
    "        scores = cross_val_score(clf,X,y,cv=5)\n",
    "        results = results.append({'n_estimators':n,'max_depth':m,'mean_score':scores.mean()},ignore_index=True)\n",
    "    \n",
    "results.sort_values(by='mean_score',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>max_features</th>\n",
       "      <th>mean_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>200.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.840686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.838445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>100.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.837316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.836198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.835075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.835068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.833932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.833932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>100.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.832827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.832821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>200.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.832821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>200.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.832815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>200.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.832802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.831710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>200.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.831704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.831691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.831685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.830593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>200.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.830586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>200.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.830580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>100.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.830574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.829475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.829469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>200.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.829463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.829457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>100.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.829450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>200.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.829444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.829444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>200.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.828358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.827228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>200.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.824949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>100.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.824937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.823832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.823819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.823813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>200.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.818233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.799049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.797951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.796834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.796821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>200.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.796821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.796821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.794561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>200.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.794543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>200.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.793444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.791197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.788956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>200.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.788956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_estimators  max_depth  max_features  mean_score\n",
       "27         200.0        8.0          20.0    0.840686\n",
       "11         100.0        8.0          20.0    0.838445\n",
       "14         100.0       10.0          15.0    0.837316\n",
       "43        1000.0        8.0          20.0    0.836198\n",
       "46        1000.0       10.0          15.0    0.835075\n",
       "47        1000.0       10.0          20.0    0.835068\n",
       "45        1000.0       10.0          10.0    0.833932\n",
       "38        1000.0        5.0          15.0    0.833932\n",
       "15         100.0       10.0          20.0    0.832827\n",
       "6          100.0        5.0          15.0    0.832821\n",
       "30         200.0       10.0          15.0    0.832821\n",
       "31         200.0       10.0          20.0    0.832815\n",
       "20         200.0        5.0           5.0    0.832802\n",
       "42        1000.0        8.0          15.0    0.831710\n",
       "23         200.0        5.0          20.0    0.831704\n",
       "37        1000.0        5.0          10.0    0.831691\n",
       "41        1000.0        8.0          10.0    0.831685\n",
       "9          100.0        8.0          10.0    0.830593\n",
       "26         200.0        8.0          15.0    0.830586\n",
       "25         200.0        8.0          10.0    0.830580\n",
       "13         100.0       10.0          10.0    0.830574\n",
       "5          100.0        5.0          10.0    0.829475\n",
       "7          100.0        5.0          20.0    0.829469\n",
       "21         200.0        5.0          10.0    0.829463\n",
       "39        1000.0        5.0          20.0    0.829457\n",
       "10         100.0        8.0          15.0    0.829450\n",
       "22         200.0        5.0          15.0    0.829444\n",
       "40        1000.0        8.0           5.0    0.829444\n",
       "29         200.0       10.0          10.0    0.828358\n",
       "8          100.0        8.0           5.0    0.827228\n",
       "24         200.0        8.0           5.0    0.824949\n",
       "12         100.0       10.0           5.0    0.824937\n",
       "4          100.0        5.0           5.0    0.823832\n",
       "44        1000.0       10.0           5.0    0.823819\n",
       "36        1000.0        5.0           5.0    0.823813\n",
       "28         200.0       10.0           5.0    0.818233\n",
       "0          100.0        2.0           5.0    0.799049\n",
       "2          100.0        2.0          15.0    0.797951\n",
       "34        1000.0        2.0          15.0    0.796834\n",
       "3          100.0        2.0          20.0    0.796821\n",
       "19         200.0        2.0          20.0    0.796821\n",
       "35        1000.0        2.0          20.0    0.796821\n",
       "33        1000.0        2.0          10.0    0.794561\n",
       "16         200.0        2.0           5.0    0.794543\n",
       "17         200.0        2.0          10.0    0.793444\n",
       "1          100.0        2.0          10.0    0.791197\n",
       "32        1000.0        2.0           5.0    0.788956\n",
       "18         200.0        2.0          15.0    0.788956"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_estimators = [100,200,1000]\n",
    "max_depth = [2,5,8,10]\n",
    "max_features = [5,10,15,20]\n",
    "results = pd.DataFrame(columns=['n_estimators','max_depth','max_features','mean_score'])\n",
    "\n",
    "for n in n_estimators:\n",
    "    for m in max_depth:\n",
    "        for f in max_features:\n",
    "            clf = RFC(n_estimators=n,max_depth=m,max_features=f,criterion='entropy')\n",
    "            scores = cross_val_score(clf,X,y,cv=5)\n",
    "            results = results.append({'n_estimators':n,'max_depth':m,'max_features':f,'mean_score':scores.mean()},ignore_index=True)\n",
    "    \n",
    "results.sort_values(by='mean_score',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=5, max_features=5, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=200, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_RFC = RFC(n_estimators=200,max_depth=5,max_features=5,criterion='entropy')\n",
    "clf_RFC.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhcAAAHVCAYAAABCEdlqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0VVJLiIiIqKr/h8dVHyTs4XEHwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcae9a76e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importance = pd.Series(clf_RFC.feature_importances_,index=X.columns)\n",
    "feature_importance.sort_values().plot(kind='barh',figsize=(8,8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_RFC.fit(X[:700],y[:700])\n",
    "predictions = clf_RFC.predict(X[700:])\n",
    "errors = X[700:][predictions != y[700:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass             2.214286\n",
       "Age               30.696429\n",
       "SibSp              0.321429\n",
       "Parch              0.285714\n",
       "Fare              40.305657\n",
       "Gender             0.392857\n",
       "Alone              0.642857\n",
       "Title_Dr           0.000000\n",
       "Title_Master       0.035714\n",
       "Title_Military     0.035714\n",
       "Title_Miss         0.285714\n",
       "Title_Mr           0.535714\n",
       "Title_Mrs          0.107143\n",
       "Title_Rev          0.000000\n",
       "Title_Royalty      0.000000\n",
       "Deck_A             0.000000\n",
       "Deck_B             0.071429\n",
       "Deck_C             0.107143\n",
       "Deck_D             0.035714\n",
       "Deck_E             0.178571\n",
       "Deck_F             0.000000\n",
       "Deck_G             0.000000\n",
       "Deck_T             0.000000\n",
       "Deck_X             0.607143\n",
       "Embarked_C         0.214286\n",
       "Embarked_Q         0.071429\n",
       "Embarked_S         0.714286\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_RFC = clf_RFC.predict(submit)\n",
    "submission_RFC = pd.DataFrame({ 'PassengerId': test['PassengerId'], 'Survived': pd.Series(predictions_RFC)})\n",
    "submission_RFC.to_csv('submission_RFC.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient boosting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier as GBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>mean_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.832846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200.0</td>\n",
       "      <td>0.832815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500.0</td>\n",
       "      <td>0.826111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.802521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.799144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_estimators  mean_score\n",
       "0         100.0    0.832846\n",
       "1         200.0    0.832815\n",
       "2         500.0    0.826111\n",
       "3        1000.0    0.802521\n",
       "4        2000.0    0.799144"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_estimators = [100,200,500,1000,2000]\n",
    "results = pd.DataFrame(columns=['n_estimators','mean_score'])\n",
    "\n",
    "for n in n_estimators:\n",
    "        clf = GBC(n_estimators=n)\n",
    "        scores = cross_val_score(clf,X,y,cv=5)\n",
    "        results = results.append({'n_estimators':n,'mean_score':scores.mean()},ignore_index=True)\n",
    "    \n",
    "results.sort_values(by='mean_score',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_GBC = GBC(n_estimators=100)\n",
    "clf_GBC.fit(X,y)\n",
    "predictions_GBC = clf_GBC.predict(submit)\n",
    "submission_GBC = pd.DataFrame({ 'PassengerId': test['PassengerId'], 'Survived': pd.Series(predictions_GBC)})\n",
    "submission_GBC.to_csv('submission_GBC.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression as LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>penalty</th>\n",
       "      <th>C</th>\n",
       "      <th>fit_intercept</th>\n",
       "      <th>mean_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>l1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>0.829431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>l1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>False</td>\n",
       "      <td>0.828314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>l1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>False</td>\n",
       "      <td>0.828314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>l2</td>\n",
       "      <td>1.8</td>\n",
       "      <td>False</td>\n",
       "      <td>0.828314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>l2</td>\n",
       "      <td>2.1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.828314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>l2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.828314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>l1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.828308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>l1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.828308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>l2</td>\n",
       "      <td>1.8</td>\n",
       "      <td>True</td>\n",
       "      <td>0.828308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>l1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>0.827197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   penalty    C fit_intercept  mean_score\n",
       "45      l1  1.2         False    0.829431\n",
       "47      l1  1.3         False    0.828314\n",
       "49      l1  1.4         False    0.828314\n",
       "17      l2  1.8         False    0.828314\n",
       "23      l2  2.1         False    0.828314\n",
       "20      l2  2.0          True    0.828314\n",
       "41      l1  1.0         False    0.828308\n",
       "43      l1  1.1         False    0.828308\n",
       "16      l2  1.8          True    0.828308\n",
       "44      l1  1.2          True    0.827197"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penalty = ['l2','l1']\n",
    "C = np.arange(1,3,0.1)\n",
    "fit_intercept = [True,False]\n",
    "results = pd.DataFrame(columns=['penalty','C','fit_intercept','mean_score'])\n",
    "\n",
    "for p in penalty:\n",
    "    for c in C:\n",
    "        for f in fit_intercept:\n",
    "            reg = LR(penalty=p,C=c,fit_intercept=f)\n",
    "            scores = cross_val_score(reg,X,y,cv=5)\n",
    "            results = results.append({'penalty':p,'C':c,'fit_intercept':f,'mean_score':scores.mean()},ignore_index=True)\n",
    "    \n",
    "results.sort_values(by='mean_score',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.2, class_weight=None, dual=False, fit_intercept=False,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_LR = LR(C=1.2,penalty='l1',fit_intercept=False)\n",
    "reg_LR.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_LR = reg_LR.predict(submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_LR = pd.DataFrame({ 'PassengerId': test['PassengerId'], 'Survived': pd.Series(predictions_LR)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_LR.to_csv('submission_LR.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### K-nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier as KNC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_neighbors</th>\n",
       "      <th>mean_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.699357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.0</td>\n",
       "      <td>0.695961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.0</td>\n",
       "      <td>0.694843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.692621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.691504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.0</td>\n",
       "      <td>0.691472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.691453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.688139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.688095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.685898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_neighbors  mean_score\n",
       "17         18.0    0.699357\n",
       "18         19.0    0.695961\n",
       "15         16.0    0.694843\n",
       "14         15.0    0.692621\n",
       "9          10.0    0.691504\n",
       "16         17.0    0.691472\n",
       "13         14.0    0.691453\n",
       "11         12.0    0.688139\n",
       "12         13.0    0.688095\n",
       "10         11.0    0.685898"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_neighbors = range(1,20)\n",
    "results = pd.DataFrame(columns=['n_neighbors','mean_score'])\n",
    "\n",
    "for n in n_neighbors:\n",
    "    clf = KNC(n_neighbors=n)\n",
    "    scores = cross_val_score(clf,X,y,cv=5)\n",
    "    results = results.append({'n_neighbors':n,'mean_score':scores.mean()},ignore_index=True)\n",
    "    \n",
    "results.sort_values(by='mean_score',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
